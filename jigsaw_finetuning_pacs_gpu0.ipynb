{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cartoon-photo-sketch to art_painting - 31 jigsaw classes, split 0\n",
      "Using Caffe AlexNet\n",
      "Dataset size: train 3000, val 793, test 2048\n",
      "Step size: 24\n",
      "Saving to /home/enoon/code/2018/JigsawDA/myJigsaw/utils/../logs/tmp/cartoon-photo-sketch_to_art_painting/eps30_bs128_lr0.001_class7_jigClass31_jigWeight0.4_TAll_bias0.8_classifyOnlySane_146\n",
      "New epoch - lr: 0.001\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from data import data_helper\n",
    "from data.data_helper import available_datasets\n",
    "from models import model_factory\n",
    "from optimizer.optimizer_helper import get_optim_and_scheduler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "from utils.Logger import Logger\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from train_jigsaw import Trainer\n",
    "from utils import vis\n",
    "\n",
    "class Container():\n",
    "    pass\n",
    "\n",
    "args = Container()\n",
    "args.batch_size = 128\n",
    "args.n_classes = 7\n",
    "args.learning_rate = 0.001\n",
    "args.epochs = 30\n",
    "args.network = \"caffenet\"\n",
    "args.val_size = 0.1\n",
    "args.tf_logger = True\n",
    "args.folder_name = \"tmp\" # odd_one_out\n",
    "args.jigsaw_n_classes = 31\n",
    "\n",
    "args.train_all = True\n",
    "# args.jig_weight = 0.9\n",
    "# args.bias_whole_image = 0.8\n",
    "args.TTA = False\n",
    "args.suffix = \"\"\n",
    "args.image_size = 222\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "source = sorted([\"photo\", \"cartoon\", \"sketch\", \"art_painting\"])\n",
    "args.classify_only_sane = True\n",
    "args.limit_samples = 1000\n",
    "\n",
    "for args.jig_weight in [0.4]: \n",
    "    for args.bias_whole_image in [0.8]:\n",
    "        for k, x in enumerate(source):\n",
    "            args.source = source[:k]+source[k+1:]\n",
    "            args.target = x\n",
    "            for i in range(3):\n",
    "                print(\"\\n%s to %s - %d jigsaw classes, split %d\" % (\"-\".join(args.source), \n",
    "                                                                  args.target, \n",
    "                                                                  args.jigsaw_n_classes,\n",
    "                                                                  i))\n",
    "                trainer = Trainer(args, device)\n",
    "                trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = sorted([\"photo\", \"cartoon\", \"sketch\", \"art_painting\"])\n",
    "args.epochs = 30\n",
    "args.jigsaw_n_classes = 31\n",
    "for args.bias_whole_image in [None, 0.1, 0.3, 0.5]:\n",
    "    for args.classify_only_sane in [True, False]:\n",
    "        print(\"===============================\\n\")\n",
    "        for k, x in enumerate(source):\n",
    "            args.source = source[:k]+source[k+1:]\n",
    "            args.target = x\n",
    "            for i in range(3):\n",
    "                print(\"\\n%s to %s - %d jigsaw classes, split %d\" % (\"-\".join(args.source), \n",
    "                                                                  args.target, \n",
    "                                                                  args.jigsaw_n_classes,\n",
    "                                                                  i))\n",
    "                trainer = Trainer(args, device)\n",
    "                trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = sorted([\"photo\", \"cartoon\", \"sketch\", \"art_painting\"])\n",
    "for args.jigsaw_n_classes in [1,3,5,10,20]:\n",
    "    args.epochs = int((80/95)*args.jigsaw_n_classes+15)\n",
    "    for k, x in enumerate(source):\n",
    "        args.source = source[:k]+source[k+1:]\n",
    "        args.target = x\n",
    "        for i in range(3):\n",
    "            print(\"\\n%s to %s - %d jigsaw classes, split %d\" % (\"-\".join(args.source), \n",
    "                                                              args.target, \n",
    "                                                              args.jigsaw_n_classes,\n",
    "                                                              i))\n",
    "            trainer = Trainer(args, device)\n",
    "            trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(args, device)\n",
    "logger, model = trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(args, device)\n",
    "logger, model = trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "print(100*(logger.val_acc[\"class\"][-1] + logger.val_acc[\"class\"][-2])/2.)\n",
    "vis.view_training(logger, \"%s->%s eps:%d jigweight:%.1f\" % (\"-\".join(args.source),\n",
    "                                                            args.target,args.epochs, args.jig_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "for k,v in logger.losses.items():\n",
    "    ax1.plot(v, label=k)\n",
    "    l = len(v)\n",
    "updates = l / len(logger.val_acc)\n",
    "print(updates)\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(0,l,int(updates)), logger.val_acc, label=\"Test acc\", c='g')\n",
    "plt.legend()\n",
    "plt.title(\"%s->%s eps:%d jigweight:%.2f\" % (str(source),target,epochs, jig_weight))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "for k,v in logger.losses.items():\n",
    "    ax1.plot(v, label=k)\n",
    "    l = len(v)\n",
    "updates = l / len(logger.val_acc)\n",
    "print(updates)\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(0,l,int(updates)), logger.val_acc, label=\"Test acc\", c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_plt(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "conv1 = models.alexnet(pretrained=True).features[0] #model_ft.features[0]\n",
    "tmp = conv1.weight.cpu().data\n",
    "tmp = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "plt.imshow(to_plt(tmp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "conv1 = model_ft.features[0]\n",
    "tmp = conv1.weight.cpu().data\n",
    "tmp = torchvision.utils.make_grid(tmp,normalize=True)\n",
    "plt.imshow(to_plt(tmp))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(memory[\"train\"], label=\"train\")\n",
    "plt.plot(memory[\"val\"], label=\"val\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# iter_c = iter(train_datasets)\n",
    "\n",
    "# for x in range(5):\n",
    "#     tmp = next(iter_c)\n",
    "#     image = to_plt(tmp[0])\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from data.data_helper import get_val_dataloader, get_train_dataloader\n",
    "from os.path import join, dirname\n",
    "# from data.JigsawLoader import JigsawTestDataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "loader = get_val_dataloader(\"photo\",31,batch_size=10,multi=False)\n",
    "# loader, _ = get_train_dataloader([\"photo\"],31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_plt(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    return inp\n",
    "\n",
    "# dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)\n",
    "# test = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
    "iter_c = iter(loader)\n",
    "(tmp, v, c), d = next(iter_c)\n",
    "\n",
    "for x in range(tmp.shape[0]):\n",
    "#     image = tmp[0, x]\n",
    "    image = torchvision.utils.make_grid(tmp[x],1,normalize=True)\n",
    "    plt.imshow(to_plt(image))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# print(v.max(), v.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.max(), tmp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.JigsawLoader import JigsawDataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class JigsawTestDataset(JigsawDataset):\n",
    "    def __init__(self, *args, **xargs):\n",
    "        super().__init__(*args, **xargs)\n",
    "        self._augment_tile = transforms.Compose([\n",
    "#             transforms.RandomCrop(64),\n",
    "            transforms.Resize((75, 75), Image.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        framename = self.data_path + '/' + self.names[index]\n",
    "        img = Image.open(framename).convert('RGB')\n",
    "        img = self._image_transformer(img)\n",
    "\n",
    "        w = float(img.size[0]) / self.grid_size\n",
    "        n_grids = self.grid_size ** 2\n",
    "        tiles = [None] * n_grids\n",
    "        for n in range(n_grids):\n",
    "            y = int(n / self.grid_size)\n",
    "            x = n % self.grid_size\n",
    "            tile = img.crop([x * w, y * w, (x + 1) * w, (y + 1) * w])\n",
    "            tile = self._augment_tile(tile)\n",
    "            tiles[n] = tile\n",
    "\n",
    "        data = torch.stack(tiles, 0)\n",
    "        return self.returnFunc(data), 0, int(self.labels[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JigsawTestDataset(\"\", join('data/txt_lists', 'dslr_train.txt'), patches=False, classes=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([np.random.randint(9) for x in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = np.load(\"permutations_31.npy\")\n",
    "perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stuff():\n",
    "    print(\"done\")\n",
    "\n",
    "a = {\"ciao\":0}\n",
    "try:\n",
    "    a[\"cigao\"]\n",
    "except KeyError:\n",
    "    stuff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(10))\n",
    "a[:None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
